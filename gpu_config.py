#!/usr/bin/env python
# coding: utf-8
"""
GPU Configuration Helper
C·∫•u h√¨nh GPU cho TensorFlow/Keras training
"""

import tensorflow as tf
import os


def configure_gpu(memory_growth=True, gpu_id=None):
    """
    C·∫•u h√¨nh GPU cho TensorFlow
    
    Parameters:
    -----------
    memory_growth : bool
        N·∫øu True, ch·ªâ allocate GPU memory khi c·∫ßn (tr√°nh allocate to√†n b·ªô)
    gpu_id : int or None
        Ch·ªâ ƒë·ªãnh GPU c·ª• th·ªÉ (0, 1, ...). None = s·ª≠ d·ª•ng t·∫•t c·∫£ GPU
    
    Returns:
    --------
    dict : Th√¥ng tin v·ªÅ GPU configuration
    """
    gpus = tf.config.list_physical_devices('GPU')
    
    if not gpus:
        print("‚ö†Ô∏è  Kh√¥ng ph√°t hi·ªán GPU, s·∫Ω s·ª≠ d·ª•ng CPU")
        return {
            'gpu_available': False,
            'gpu_count': 0,
            'gpu_names': []
        }
    
    try:
        if gpu_id is not None:
            # Ch·ªâ s·ª≠ d·ª•ng GPU c·ª• th·ªÉ
            if gpu_id < len(gpus):
                tf.config.set_visible_devices(gpus[gpu_id], 'GPU')
                gpus = [gpus[gpu_id]]
            else:
                print(f"‚ö†Ô∏è  GPU {gpu_id} kh√¥ng t·ªìn t·∫°i, s·ª≠ d·ª•ng GPU ƒë·∫ßu ti√™n")
        
        # C·∫•u h√¨nh memory growth
        if memory_growth:
            for gpu in gpus:
                tf.config.experimental.set_memory_growth(gpu, True)
        
        # Log th√¥ng tin GPU
        gpu_names = [gpu.name for gpu in gpus]
        print(f"‚úÖ GPU ƒë∆∞·ª£c ph√°t hi·ªán: {len(gpus)} GPU(s)")
        for i, gpu in enumerate(gpus):
            print(f"   GPU {i}: {gpu.name}")
            if hasattr(gpu, 'device_details'):
                print(f"      Details: {gpu.device_details}")
        
        return {
            'gpu_available': True,
            'gpu_count': len(gpus),
            'gpu_names': gpu_names
        }
        
    except RuntimeError as e:
        print(f"‚ùå L·ªói c·∫•u h√¨nh GPU: {e}")
        return {
            'gpu_available': False,
            'gpu_count': 0,
            'gpu_names': [],
            'error': str(e)
        }


def disable_gpu():
    """
    V√¥ hi·ªáu h√≥a GPU, ch·ªâ s·ª≠ d·ª•ng CPU
    """
    os.environ['CUDA_VISIBLE_DEVICES'] = '-1'
    print("üîß GPU ƒë√£ ƒë∆∞·ª£c v√¥ hi·ªáu h√≥a, s·ª≠ d·ª•ng CPU")


def enable_gpu(gpu_id=None):
    """
    K√≠ch ho·∫°t GPU
    
    Parameters:
    -----------
    gpu_id : int or None
        Ch·ªâ ƒë·ªãnh GPU c·ª• th·ªÉ. None = s·ª≠ d·ª•ng t·∫•t c·∫£
    """
    if gpu_id is not None:
        os.environ['CUDA_VISIBLE_DEVICES'] = str(gpu_id)
        print(f"üîß Ch·ªâ s·ª≠ d·ª•ng GPU {gpu_id}")
    else:
        if 'CUDA_VISIBLE_DEVICES' in os.environ:
            del os.environ['CUDA_VISIBLE_DEVICES']
        print("üîß S·ª≠ d·ª•ng t·∫•t c·∫£ GPU c√≥ s·∫µn")


def get_gpu_info():
    """
    L·∫•y th√¥ng tin chi ti·∫øt v·ªÅ GPU
    
    Returns:
    --------
    dict : Th√¥ng tin GPU
    """
    gpus = tf.config.list_physical_devices('GPU')
    
    if not gpus:
        return {
            'gpu_available': False,
            'gpu_count': 0
        }
    
    info = {
        'gpu_available': True,
        'gpu_count': len(gpus),
        'gpus': []
    }
    
    for i, gpu in enumerate(gpus):
        gpu_info = {
            'id': i,
            'name': gpu.name
        }
        
        # Th·ª≠ l·∫•y th√™m th√¥ng tin n·∫øu c√≥
        try:
            details = tf.config.experimental.get_device_details(gpu)
            if details:
                gpu_info['details'] = details
        except:
            pass
        
        info['gpus'].append(gpu_info)
    
    return info


def print_gpu_summary():
    """
    In t√≥m t·∫Øt th√¥ng tin GPU
    """
    print("=" * 50)
    print("GPU CONFIGURATION SUMMARY")
    print("=" * 50)
    
    info = get_gpu_info()
    
    if info['gpu_available']:
        print(f"‚úÖ {info['gpu_count']} GPU(s) available:")
        for gpu in info['gpus']:
            print(f"   - {gpu['name']}")
    else:
        print("‚ö†Ô∏è  No GPU available, using CPU")
    
    print("=" * 50)


# Auto-configure khi import (optional)
if __name__ == "__main__":
    # Test GPU configuration
    print_gpu_summary()
    config = configure_gpu()
    print(f"\nConfiguration result: {config}")

